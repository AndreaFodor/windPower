{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80161ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d76639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Power output HQ dataset (with only wind powercolumn)\n",
    "power_df = pd.read_csv(\"../historique-production-electricite-quebec.csv\")[[\"Date\",\"Wind\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e5cfc",
   "metadata": {},
   "source": [
    "There are some duplicate dates due to time-zone related issue. I am printing them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59aa7c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated places:\n",
      "                            Date     Wind\n",
      "5476   2020-11-01T01:30:00-05:00  2737.00\n",
      "14385  2021-11-07T01:30:00-05:00  2584.00\n",
      "22988  2019-11-03T01:30:00-05:00   686.00\n",
      "28901  2022-11-06T01:30:00-05:00  2576.00\n",
      "41485  2023-03-12T03:30:00-04:00   142.97\n"
     ]
    }
   ],
   "source": [
    "#Checking duplicate 'Date' in the original dataset\n",
    "power_df_strtime = power_df\n",
    "print(\"Duplicated places:\")\n",
    "print(power_df_strtime[power_df_strtime['Date'].duplicated()])\n",
    "\n",
    "#for trouble in [5476,14385,22988,28901,41485]:\n",
    "#    print(f\"Displaying around troublesome index: {trouble}\")\n",
    "#    print(power_df.loc[trouble-2:trouble+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8471da",
   "metadata": {},
   "source": [
    "Convert all time strings to pandas Timestamp objects with UTC flag true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64fb1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format time from string to TimeStamp and converted all times to UTC\n",
    "power_df['Date'] = pd.to_datetime(power_df['Date'], utc =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4809c",
   "metadata": {},
   "source": [
    "But this shifts some datapoints from Year N to Year N+1, so we shift everything by 5 hours so that the first hour is 2019-01-01 00:00:00 and the last hour is 2023-12-31 23:00:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "324ee93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df['Date'] = power_df['Date'].apply(lambda x: x - pd.Timedelta(hours=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9be7c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#power_df['TimeZone'] = power_df['Date'].apply(lambda x: x.utcoffset())\n",
    "#print(power_df['TimeZone'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d4ec9",
   "metadata": {},
   "source": [
    "After this, we can treat our data time-zone independent. We we remove the time-zone information all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c30c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df['Date'] = power_df['Date'].dt.tz_localize(None)#remove time-zone information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9adcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manim\\AppData\\Local\\Temp\\ipykernel_8904\\4099056116.py:5: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  power_df['Date'] = power_df['Date'].apply(lambda x: x.floor('H'))\n"
     ]
    }
   ],
   "source": [
    "#Sort the dataset by date\n",
    "power_df = power_df.sort_values('Date')\n",
    "\n",
    "#Replace original 'Date' column by Year:MonthDay:Hour:00 for consistant formating with weather data\n",
    "power_df['Date'] = power_df['Date'].apply(lambda x: x.floor('H'))\n",
    "\n",
    "#Adding year and month/day in the dataset\n",
    "power_df['Year'] = power_df['Date'].apply(lambda x: x.year)                     #adding a year column\n",
    "power_df['MonthDay'] = power_df['Date'].apply(lambda x: x.strftime('%m-%d'))    #adding a Month/Day column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03bda8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.datetime64('2023-12-31T23:00:00.000000000')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if the last entry in inside 2023\n",
    "np.array(power_df['Date'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bae07e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manim\\AppData\\Local\\Temp\\ipykernel_3796\\588311194.py:1: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  timestamps = pd.date_range(start=\"2019-01-01 00:00:00\", end=\"2023-12-31 23:00:00\", freq=\"H\")\n"
     ]
    }
   ],
   "source": [
    "timestamps = pd.date_range(start=\"2019-01-01 00:00:00\", end=\"2023-12-31 23:00:00\", freq=\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d1d58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing timestamps:\n",
      "DatetimeIndex(['2019-11-03', '2020-11-01', '2021-11-07', '2022-11-06',\n",
      "               '2023-11-05'],\n",
      "              dtype='datetime64[ns]', freq=None) 5\n",
      "Duplicate timestamps:\n",
      "22988   2019-11-03 01:00:00\n",
      "17194   2019-11-03 01:00:00\n",
      "5475    2020-11-01 01:00:00\n",
      "5476    2020-11-01 01:00:00\n",
      "14385   2021-11-07 01:00:00\n",
      "14383   2021-11-07 01:00:00\n",
      "28901   2022-11-06 01:00:00\n",
      "11380   2022-11-06 01:00:00\n",
      "589     2023-03-12 02:00:00\n",
      "41485   2023-03-12 02:00:00\n",
      "Name: Date, dtype: datetime64[ns] 10\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Find missing timestamps\n",
    "missing = timestamps.difference(power_df['Date'])\n",
    "print(\"Missing timestamps:\")\n",
    "print(missing, len(missing))\n",
    "\n",
    "# Step 4: Find duplicate timestamps\n",
    "duplicates = power_df['Date'][power_df['Date'].duplicated(keep=False)]\n",
    "print(\"Duplicate timestamps:\")\n",
    "print(duplicates, len(duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f1c9f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1718\n"
     ]
    }
   ],
   "source": [
    "print(len(power_df[(power_df['Date'] >= pd.Timestamp('2023-01-01 00:00:00') - pd.Timedelta(hours=12)) & \n",
    "                (power_df['Date'] <= pd.Timestamp('2023-03-12 12:00:00') + pd.Timedelta(hours=12))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08f7cf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(power_df[(power_df['Date'] >= pd.Timestamp('2020-03-08 00:00:00')) & \n",
    "               (power_df['Date'] <= pd.Timestamp('2020-03-08 23:00:00'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e049ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8760\n",
      "8784\n",
      "8760\n",
      "8760\n",
      "8760\n"
     ]
    }
   ],
   "source": [
    "for year in range(2019, 2024):\n",
    "    print(len(power_df[power_df['Year'].astype(int) == year]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd4ed969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nearby rows for duplicated timestamp: 2019-11-03 01:00:00\n",
      "                     Date   Wind  Year MonthDay\n",
      "17192 2019-11-02 22:00:00  795.0  2019    11-02\n",
      "17193 2019-11-02 23:00:00  773.0  2019    11-02\n",
      "22988 2019-11-03 01:00:00  686.0  2019    11-03\n",
      "17194 2019-11-03 01:00:00  712.0  2019    11-03\n",
      "22989 2019-11-03 02:00:00  702.0  2019    11-03\n",
      "17195 2019-11-03 03:00:00  670.0  2019    11-03\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2020-11-01 01:00:00\n",
      "                     Date    Wind  Year MonthDay\n",
      "20062 2020-10-31 22:00:00  2202.0  2020    10-31\n",
      "5474  2020-10-31 23:00:00  2459.0  2020    10-31\n",
      "5475  2020-11-01 01:00:00  2212.0  2020    11-01\n",
      "5476  2020-11-01 01:00:00  2737.0  2020    11-01\n",
      "5477  2020-11-01 02:00:00  2723.0  2020    11-01\n",
      "5478  2020-11-01 03:00:00  2400.0  2020    11-01\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2021-11-07 01:00:00\n",
      "                     Date    Wind  Year MonthDay\n",
      "31894 2021-11-06 22:00:00  2855.0  2021    11-06\n",
      "31895 2021-11-06 23:00:00  2819.0  2021    11-06\n",
      "14385 2021-11-07 01:00:00  2584.0  2021    11-07\n",
      "14383 2021-11-07 01:00:00  2689.0  2021    11-07\n",
      "31896 2021-11-07 02:00:00  2054.0  2021    11-07\n",
      "37596 2021-11-07 03:00:00  2220.0  2021    11-07\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2022-11-06 01:00:00\n",
      "                     Date    Wind  Year MonthDay\n",
      "40449 2022-11-05 22:00:00  2564.0  2022    11-05\n",
      "11379 2022-11-05 23:00:00  2634.0  2022    11-05\n",
      "28901 2022-11-06 01:00:00  2576.0  2022    11-06\n",
      "11380 2022-11-06 01:00:00  2592.0  2022    11-06\n",
      "28902 2022-11-06 02:00:00  2606.0  2022    11-06\n",
      "28903 2022-11-06 03:00:00  2720.0  2022    11-06\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2023-03-12 02:00:00\n",
      "                     Date    Wind  Year MonthDay\n",
      "32815 2023-03-11 23:00:00  315.72  2023    03-11\n",
      "588   2023-03-12 00:00:00  220.03  2023    03-12\n",
      "32816 2023-03-12 01:00:00  138.07  2023    03-12\n",
      "589   2023-03-12 02:00:00  111.65  2023    03-12\n",
      "41485 2023-03-12 02:00:00  142.97  2023    03-12\n",
      "32817 2023-03-12 03:00:00  154.54  2023    03-12\n",
      "41486 2023-03-12 04:00:00  133.23  2023    03-12\n"
     ]
    }
   ],
   "source": [
    "dupes_df = power_df[power_df['Date'].duplicated(keep=False)]\n",
    "dupes_df_sorted = dupes_df.sort_values('Date')\n",
    "\n",
    "for ts in dupes_df_sorted['Date'].unique():\n",
    "    print(f\"\\nNearby rows for duplicated timestamp: {ts}\")\n",
    "    nearby = power_df[(power_df['Date'] >= ts - pd.Timedelta(hours=3)) & \n",
    "                (power_df['Date'] <= ts + pd.Timedelta(hours=2))]\n",
    "    print(nearby.sort_values('Date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084354bd",
   "metadata": {},
   "source": [
    "### The above confirms that all those duplicated values were when the time zone shifted. We would need to manually change these 5 entries.\n",
    "\n",
    "All those 01:00 will become 00:00. But I'm not sure how to deal with the duplicate 2023-03-12 02:00:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a654e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We shall manually replace them here (or some better way that we need think later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57daaec",
   "metadata": {},
   "source": [
    "# Weather files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c2bed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File names for weather data of different farms\n",
    "weather_files = os.listdir('../windfarm_weather_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc0d60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_wdf = pd.read_csv(f\"../windfarm_weather_data/{weather_files[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd975ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_direction_10m</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01T00:00</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>83</td>\n",
       "      <td>16.8</td>\n",
       "      <td>138</td>\n",
       "      <td>Arthabaska wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01T01:00</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>88</td>\n",
       "      <td>18.7</td>\n",
       "      <td>140</td>\n",
       "      <td>Arthabaska wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01T02:00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>90</td>\n",
       "      <td>19.7</td>\n",
       "      <td>142</td>\n",
       "      <td>Arthabaska wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01T03:00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>87</td>\n",
       "      <td>18.9</td>\n",
       "      <td>140</td>\n",
       "      <td>Arthabaska wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01T04:00</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>99</td>\n",
       "      <td>13.2</td>\n",
       "      <td>119</td>\n",
       "      <td>Arthabaska wind farm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              time  temperature_2m  relative_humidity_2m  \\\n",
       "0           0  2019-01-01T00:00            -0.3                    83   \n",
       "1           1  2019-01-01T01:00            -0.2                    88   \n",
       "2           2  2019-01-01T02:00             0.2                    90   \n",
       "3           3  2019-01-01T03:00             0.6                    87   \n",
       "4           4  2019-01-01T04:00            -0.1                    99   \n",
       "\n",
       "   wind_speed_10m  wind_direction_10m              location  \n",
       "0            16.8                 138  Arthabaska wind farm  \n",
       "1            18.7                 140  Arthabaska wind farm  \n",
       "2            19.7                 142  Arthabaska wind farm  \n",
       "3            18.9                 140  Arthabaska wind farm  \n",
       "4            13.2                 119  Arthabaska wind farm  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farm_wdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a7f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just wanted to check how the dataset look by looking at the first farm\n",
    "farm_wdf = pd.read_csv(f\"../windfarm_weather_data/{weather_files[0]}\")\n",
    "\n",
    "farm_wdf['time'] = pd.to_datetime(farm_wdf['time'], utc= True)                  #convert time to Timestamp object\n",
    "farm_wdf = farm_wdf.sort_values('time')                                         #sort values using time\n",
    "\n",
    "farm_wdf['time'] = farm_wdf['time'].apply(lambda x: x - pd.Timedelta(hours=5))  #drag the times to usual days in ET\n",
    "\n",
    "farm_wdf['Year'] = farm_wdf['time'].apply(lambda x: x.year)                     #adding a year column\n",
    "farm_wdf['MonthDay'] = farm_wdf['time'].apply(lambda x: x.strftime('%m-%d'))    #adding Month/Day as a column\n",
    "\n",
    "#Remove data from 2024 as we don't have power data from 2024\n",
    "farm_wdf = farm_wdf[farm_wdf['Year'].astype(str) != '2024']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52daf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for farm_name in weather_files:\n",
    "    farm_wdf = pd.read_csv(f\"../windfarm_weather_data/{farm_name}\")\n",
    "    farm_wdf['time'] = pd.to_datetime(farm_wdf['time'])                             #convert time to Timestamp object\n",
    "    farm_wdf = farm_wdf.sort_values('time')                                         #sort values using time\n",
    "\n",
    "    farm_wdf['time'] = farm_wdf['time'].apply(lambda x: x - pd.Timedelta(hours=5))  #drag the times to usual days in ET    \n",
    "    if len(farm_wdf[farm_wdf['time'].duplicated()]):\n",
    "        print(f\"{farm_name.replace(' wind farm hourly weather 2019-2024.csv','')} has some duplicate timestamps.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ab29f",
   "metadata": {},
   "source": [
    "### Seems like weather files does not have any duplicates and have handled time-zone shifts well. Yay. \n",
    "\n",
    "I'll merge the datasets after I manually clean the power data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
