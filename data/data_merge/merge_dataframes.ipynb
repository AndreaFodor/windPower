{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ee74ae",
   "metadata": {},
   "source": [
    "# Summary of this notebook\n",
    "### Clean the power data:\n",
    "- For us training dataset is the data from the years 2019 through 2022. The testing dataset is the data from 2023.\n",
    "- The power data contains 5 duplicates - one from each year. This happened due to daylight saving time zone shifts. The duplicates in years 2019 through 2022 are close to each other, so we just manually changed one of the `01:00:00` entry to `00:00:00` entry based on the whichever is closed to the previous day `23:00:00` value.\n",
    "- For the year 2023, the day `03-12` has 25 entries and `11-05` has 23 entries, so the missing entry is roughly 8 months away from the missing entry. We have the following options:\n",
    "    - Remove both these two days from the testing data.\n",
    "    - Shift all the entries from `03-12` till `11-05` by one hour. Note: this is equivalent to treating \"hour 1\", \"hour 2\", and so on for a year, because one of the duplicate would become entry `hour n` and the other one would become `hour n+1` basically shifting everything by one hour after the duplicate till the missing.\n",
    "    - Pick one of the duplicate on `03-12` and remove the other. Then fill the missing entry on `11-05` with average of the nearest two.\n",
    "- Once a consensus is reached on which of the following option we choose, we will create the `main_testing_dataframe.csv`. I commented these codelines for now.\n",
    "\n",
    "### Merge Weather files (in service):\n",
    "- Pretty straight-forward as there is no time-zone issue. All times are already in a \"time-zone independent\" format in the original datasets.\n",
    "- Just merged them into the file `final_weather_only.csv`\n",
    "\n",
    "### Merge both weather and power:\n",
    "- Merged `weather_training_df`, and `power_training_df` into the file `main_training_dataframe.csv`.\n",
    "- Commented out the codelines of `main_testing_dataframe.csv` for now. This would be the merged dataframes `weather_testing_df`, and `power_testing_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80161ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9eff5b",
   "metadata": {},
   "source": [
    "# Clean the power data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d76639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Power output HQ dataset (with only wind powercolumn)\n",
    "power_df = pd.read_csv(\"../raw_data/historique-production-electricite-quebec.csv\")[[\"Date\",\"Wind\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e5cfc",
   "metadata": {},
   "source": [
    "There are some duplicate dates due to time-zone related issue. I am printing them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59aa7c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated places:\n",
      "                            Date     Wind\n",
      "5476   2020-11-01T01:30:00-05:00  2737.00\n",
      "14385  2021-11-07T01:30:00-05:00  2584.00\n",
      "22988  2019-11-03T01:30:00-05:00   686.00\n",
      "28901  2022-11-06T01:30:00-05:00  2576.00\n",
      "41485  2023-03-12T03:30:00-04:00   142.97\n"
     ]
    }
   ],
   "source": [
    "#Checking duplicate 'Date' in the original dataset\n",
    "power_df_strtime = power_df\n",
    "print(\"Duplicated places:\")\n",
    "print(power_df_strtime[power_df_strtime['Date'].duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8471da",
   "metadata": {},
   "source": [
    "Convert all time strings to pandas Timestamp objects with UTC flag true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64fb1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format time from string to TimeStamp and converted all times to UTC\n",
    "power_df['Date'] = pd.to_datetime(power_df['Date'], utc =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4809c",
   "metadata": {},
   "source": [
    "But this shifts some datapoints from Year N to Year N+1, so we shift everything by 5 hours so that the first hour is 2019-01-01 00:00:00 and the last hour is 2023-12-31 23:00:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "324ee93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df['Date'] = power_df['Date'].apply(lambda x: x - pd.Timedelta(hours=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be7c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#power_df['TimeZone'] = power_df['Date'].apply(lambda x: x.utcoffset())\n",
    "#print(power_df['TimeZone'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d4ec9",
   "metadata": {},
   "source": [
    "After this, we can treat our data time-zone independent. We we remove the time-zone information all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c30c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df['Date'] = power_df['Date'].dt.tz_localize(None)#remove time-zone information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31d356f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:30:00</td>\n",
       "      <td>151.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 05:30:00</td>\n",
       "      <td>679.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 06:30:00</td>\n",
       "      <td>829.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 08:30:00</td>\n",
       "      <td>863.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 11:30:00</td>\n",
       "      <td>639.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date    Wind\n",
       "0 2023-01-01 00:30:00  151.07\n",
       "1 2023-01-01 05:30:00  679.07\n",
       "2 2023-01-01 06:30:00  829.70\n",
       "3 2023-01-01 08:30:00  863.91\n",
       "4 2023-01-01 11:30:00  639.35"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a9adcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the dataset by date\n",
    "power_df = power_df.sort_values('Date')\n",
    "\n",
    "#Replace 'Date' column in the format Year:MonthDay:Hour:00 for consistant formating with weather data\n",
    "power_df['Date'] = power_df['Date'].apply(lambda x: x.floor('h'))\n",
    "\n",
    "#Adding year and month/day in the dataset\n",
    "power_df['Year'] = power_df['Date'].apply(lambda x: x.year)                     #adding a year column\n",
    "power_df['MonthDay'] = power_df['Date'].apply(lambda x: x.strftime('%m-%d'))    #adding a Month/Day column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80124a9",
   "metadata": {},
   "source": [
    "Renaming the `Date` column to `time` to be consistent with the weather files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16013588",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df = power_df.rename(columns={'Date' : 'time'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a726bbd",
   "metadata": {},
   "source": [
    "## Ignore this part\n",
    "I just tried to check the missing timestamps and the time-zone related issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bae07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = pd.date_range(start=\"2019-01-01 00:00:00\", end=\"2023-12-31 23:00:00\", freq=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0d1d58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing timestamps:\n",
      "DatetimeIndex(['2019-11-03', '2020-11-01', '2021-11-07', '2022-11-06',\n",
      "               '2023-11-05'],\n",
      "              dtype='datetime64[ns]', freq=None) 5\n",
      "Duplicate timestamps:\n",
      "22988   2019-11-03 01:00:00\n",
      "17194   2019-11-03 01:00:00\n",
      "5475    2020-11-01 01:00:00\n",
      "5476    2020-11-01 01:00:00\n",
      "14385   2021-11-07 01:00:00\n",
      "14383   2021-11-07 01:00:00\n",
      "28901   2022-11-06 01:00:00\n",
      "11380   2022-11-06 01:00:00\n",
      "589     2023-03-12 02:00:00\n",
      "41485   2023-03-12 02:00:00\n",
      "Name: time, dtype: datetime64[ns] 10\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Find missing timestamps\n",
    "missing = timestamps.difference(power_df['time'])\n",
    "print(\"Missing timestamps:\")\n",
    "print(missing, len(missing))\n",
    "\n",
    "# Step 4: Find duplicate timestamps\n",
    "duplicates = power_df['time'][power_df['time'].duplicated(keep=False)]\n",
    "print(\"Duplicate timestamps:\")\n",
    "print(duplicates, len(duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f1c9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(power_df[(power_df['Date'] >= pd.Timestamp('2023-01-01 00:00:00') - pd.Timedelta(hours=12)) & \n",
    "#                (power_df['Date'] <= pd.Timestamp('2023-03-12 12:00:00') + pd.Timedelta(hours=12))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08f7cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(power_df[(power_df['Date'] >= pd.Timestamp('2020-03-08 00:00:00')) & \n",
    "#               (power_df['Date'] <= pd.Timestamp('2020-03-08 23:00:00'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e049ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for year in range(2019, 2024):\n",
    "#    print(len(power_df[power_df['Year'].astype(int) == year]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e281f26",
   "metadata": {},
   "source": [
    "## Duplicate handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd4ed969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nearby rows for duplicated timestamp: 2019-11-03 01:00:00\n",
      "                     time   Wind  Year MonthDay\n",
      "17193 2019-11-02 23:00:00  773.0  2019    11-02\n",
      "22988 2019-11-03 01:00:00  686.0  2019    11-03\n",
      "17194 2019-11-03 01:00:00  712.0  2019    11-03\n",
      "22989 2019-11-03 02:00:00  702.0  2019    11-03\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2020-11-01 01:00:00\n",
      "                    time    Wind  Year MonthDay\n",
      "5474 2020-10-31 23:00:00  2459.0  2020    10-31\n",
      "5475 2020-11-01 01:00:00  2212.0  2020    11-01\n",
      "5476 2020-11-01 01:00:00  2737.0  2020    11-01\n",
      "5477 2020-11-01 02:00:00  2723.0  2020    11-01\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2021-11-07 01:00:00\n",
      "                     time    Wind  Year MonthDay\n",
      "31895 2021-11-06 23:00:00  2819.0  2021    11-06\n",
      "14385 2021-11-07 01:00:00  2584.0  2021    11-07\n",
      "14383 2021-11-07 01:00:00  2689.0  2021    11-07\n",
      "31896 2021-11-07 02:00:00  2054.0  2021    11-07\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2022-11-06 01:00:00\n",
      "                     time    Wind  Year MonthDay\n",
      "11379 2022-11-05 23:00:00  2634.0  2022    11-05\n",
      "28901 2022-11-06 01:00:00  2576.0  2022    11-06\n",
      "11380 2022-11-06 01:00:00  2592.0  2022    11-06\n",
      "28902 2022-11-06 02:00:00  2606.0  2022    11-06\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2023-03-12 02:00:00\n",
      "                     time    Wind  Year MonthDay\n",
      "588   2023-03-12 00:00:00  220.03  2023    03-12\n",
      "32816 2023-03-12 01:00:00  138.07  2023    03-12\n",
      "589   2023-03-12 02:00:00  111.65  2023    03-12\n",
      "41485 2023-03-12 02:00:00  142.97  2023    03-12\n",
      "32817 2023-03-12 03:00:00  154.54  2023    03-12\n"
     ]
    }
   ],
   "source": [
    "dupes_df = power_df[power_df['time'].duplicated(keep=False)]\n",
    "dupes_df_sorted = dupes_df.sort_values('time')\n",
    "\n",
    "for ts in dupes_df_sorted['time'].unique():\n",
    "    print(f\"\\nNearby rows for duplicated timestamp: {ts}\")\n",
    "    nearby = power_df[(power_df['time'] >= ts - pd.Timedelta(hours=2)) & \n",
    "                (power_df['time'] <= ts + pd.Timedelta(hours=1))]\n",
    "    print(nearby.sort_values('time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084354bd",
   "metadata": {},
   "source": [
    "### Manually changed the 4 duplicates in 2019-2022 from 01:00:00 to 00:00:00 and chose the closer value to 23:00:00 of previous day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5bbdeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df.at[17194, 'time'] = pd.Timestamp('2019-11-03 00:00:00')\n",
    "power_df.at[5475, 'time'] = pd.Timestamp('2020-11-01 00:00:00')\n",
    "power_df.at[14383, 'time'] = pd.Timestamp('2021-11-07 00:00:00')\n",
    "power_df.at[11380, 'time'] = pd.Timestamp('2022-11-06 00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67689aa3",
   "metadata": {},
   "source": [
    "The only duplicate present is in the year 2023, which we'll handle later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dea02d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Year</th>\n",
       "      <th>MonthDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41485</th>\n",
       "      <td>2023-03-12 02:00:00</td>\n",
       "      <td>142.97</td>\n",
       "      <td>2023</td>\n",
       "      <td>03-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time    Wind  Year MonthDay\n",
       "41485 2023-03-12 02:00:00  142.97  2023    03-12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_df[power_df['time'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f24fb2",
   "metadata": {},
   "source": [
    "### Save the modifies power file with years 2019 through 2022\n",
    "Save this power dataframe in file `../final_dataframes/training data_final_power_only.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97c69b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_training_df = power_df[power_df['time'].dt.year.astype(str) != '2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "800a555a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2019, 2020, 2021, 2022], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_training_df['time'].dt.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdc67fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset\n",
    "power_training_df.to_csv('../final_dataframes/final_training_data_power_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d5e1a",
   "metadata": {},
   "source": [
    "### WARNING for this section: this is the data for 2023 with the duplicate\n",
    "We'll deal with this once we agree on a criteria specifically for the year 2023. We'll save the dataframe letter in a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd91c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#power_testing_df = power_df[power_df['time'].dt.year.astype(str) == '2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce639965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: Save power_testing_df\n",
    "#power_testing_df.to_csv('../final_dataframes/final_testing_data_power_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57daaec",
   "metadata": {},
   "source": [
    "# Weather files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c2bed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File names for weather data of different farms\n",
    "weather_files = os.listdir('../windfarm_weather_data_in_service')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088fafd",
   "metadata": {},
   "source": [
    "### Just checking the first farm to see how the data look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03a7f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_wdf = pd.read_csv(f\"../windfarm_weather_data_in_service/{weather_files[0]}\")\n",
    "farm_wdf['time'] = pd.to_datetime(farm_wdf['time'])                  #convert time to Timestamp object\n",
    "farm_wdf = farm_wdf.sort_values('time')                                         #sort values using time\n",
    "\n",
    "#farm_wdf['Year'] = farm_wdf['time'].apply(lambda x: x.year)                     #adding a year column\n",
    "#Remove data from 2024 as we don't have power data from 2024\n",
    "farm_wdf = farm_wdf[farm_wdf['time'].dt.year.astype(str) != '2024']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6186b13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>temperature_2m_1</th>\n",
       "      <th>relative_humidity_2m_1</th>\n",
       "      <th>wind_speed_10m_1</th>\n",
       "      <th>wind_direction_10m_1</th>\n",
       "      <th>location_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>81</td>\n",
       "      <td>17.9</td>\n",
       "      <td>146</td>\n",
       "      <td>Baie-des-Sables wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>80</td>\n",
       "      <td>18.9</td>\n",
       "      <td>145</td>\n",
       "      <td>Baie-des-Sables wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>80</td>\n",
       "      <td>21.3</td>\n",
       "      <td>146</td>\n",
       "      <td>Baie-des-Sables wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>80</td>\n",
       "      <td>22.2</td>\n",
       "      <td>148</td>\n",
       "      <td>Baie-des-Sables wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>81</td>\n",
       "      <td>22.4</td>\n",
       "      <td>143</td>\n",
       "      <td>Baie-des-Sables wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43819</th>\n",
       "      <td>43819</td>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>66</td>\n",
       "      <td>16.2</td>\n",
       "      <td>302</td>\n",
       "      <td>Baie-des-Sables wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43820</th>\n",
       "      <td>43820</td>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>65</td>\n",
       "      <td>15.2</td>\n",
       "      <td>306</td>\n",
       "      <td>Baie-des-Sables wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43821</th>\n",
       "      <td>43821</td>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>65</td>\n",
       "      <td>15.0</td>\n",
       "      <td>312</td>\n",
       "      <td>Baie-des-Sables wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43822</th>\n",
       "      <td>43822</td>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>66</td>\n",
       "      <td>15.3</td>\n",
       "      <td>317</td>\n",
       "      <td>Baie-des-Sables wind farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43823</th>\n",
       "      <td>43823</td>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>68</td>\n",
       "      <td>14.9</td>\n",
       "      <td>323</td>\n",
       "      <td>Baie-des-Sables wind farm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43824 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                time  temperature_2m_1  \\\n",
       "0               0 2019-01-01 00:00:00              -7.4   \n",
       "1               1 2019-01-01 01:00:00              -7.0   \n",
       "2               2 2019-01-01 02:00:00              -7.1   \n",
       "3               3 2019-01-01 03:00:00              -6.8   \n",
       "4               4 2019-01-01 04:00:00              -6.8   \n",
       "...           ...                 ...               ...   \n",
       "43819       43819 2023-12-31 19:00:00              -6.0   \n",
       "43820       43820 2023-12-31 20:00:00              -6.2   \n",
       "43821       43821 2023-12-31 21:00:00              -6.2   \n",
       "43822       43822 2023-12-31 22:00:00              -6.4   \n",
       "43823       43823 2023-12-31 23:00:00              -6.8   \n",
       "\n",
       "       relative_humidity_2m_1  wind_speed_10m_1  wind_direction_10m_1  \\\n",
       "0                          81              17.9                   146   \n",
       "1                          80              18.9                   145   \n",
       "2                          80              21.3                   146   \n",
       "3                          80              22.2                   148   \n",
       "4                          81              22.4                   143   \n",
       "...                       ...               ...                   ...   \n",
       "43819                      66              16.2                   302   \n",
       "43820                      65              15.2                   306   \n",
       "43821                      65              15.0                   312   \n",
       "43822                      66              15.3                   317   \n",
       "43823                      68              14.9                   323   \n",
       "\n",
       "                      location_1  \n",
       "0      Baie-des-Sables wind farm  \n",
       "1      Baie-des-Sables wind farm  \n",
       "2      Baie-des-Sables wind farm  \n",
       "3      Baie-des-Sables wind farm  \n",
       "4      Baie-des-Sables wind farm  \n",
       "...                          ...  \n",
       "43819  Baie-des-Sables wind farm  \n",
       "43820  Baie-des-Sables wind farm  \n",
       "43821  Baie-des-Sables wind farm  \n",
       "43822  Baie-des-Sables wind farm  \n",
       "43823  Baie-des-Sables wind farm  \n",
       "\n",
       "[43824 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farm_wdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120be37",
   "metadata": {},
   "source": [
    "### Using some part of Desmond code to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff49681",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_wdf = pd.DataFrame()             #create a new pandas dataframe to store the merge weather files\n",
    "for filename in weather_files:\n",
    "    try: \n",
    "        df = pd.read_csv(f\"../windfarm_weather_data_in_service/{filename}\") #read each file\n",
    "        df['time'] = pd.to_datetime(df['time'])                      #convert time to pandas timestamp\n",
    "        df = df.sort_values('time')                                  #sort values using time\n",
    "        df = df[df['time'].dt.year.astype(str) != '2024']            #remove entries in 2024\n",
    "        if filename == weather_files[0]:                             #store the first dataframe   \n",
    "            merge_wdf = df\n",
    "        else:\n",
    "            #merge the other dataframes using these columns\n",
    "            merge_wdf = pd.merge(merge_wdf, df, on=['Unnamed: 0', 'time'])  \n",
    "    except:\n",
    "            print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef5a962",
   "metadata": {},
   "source": [
    "No need to have those location names in the dataframe as we already know the labels, so let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f9102a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [f\"location_{i}\" for i in range(1, 40)]\n",
    "merge_wdf = merge_wdf.drop(columns=locations, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef696def",
   "metadata": {},
   "source": [
    "Save this weather dataframe in file `../final_dataframes/final_weather_only.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fdaa578",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_wdf.to_csv('../final_dataframes/final_weather_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef49987",
   "metadata": {},
   "source": [
    "# Merge both power and weather files for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2f876b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the weather into training and testing\n",
    "weather_training_df = merge_wdf[merge_wdf['time'].dt.year.astype(str) != '2023']\n",
    "weather_testing_df = merge_wdf[merge_wdf['time'].dt.year.astype(str) == '2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae4cbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: Save weather_training_df and weather_testing_df\n",
    "#weather_training_df.to_csv('../final_dataframes/final_training_data_weather_only.csv', index=False)\n",
    "#weather_testing_df.to_csv('../final_dataframes/final_testing_data_weather_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ab462c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_training_df = pd.merge(weather_training_df, power_training_df, on=['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a882d50",
   "metadata": {},
   "source": [
    "### Finally save the main dataframe\n",
    "Our final dataframe in location `../final_dataframes/main_training_dataframe.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "023c6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_training_df.to_csv('../final_dataframes/main_training_dataframe.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec36858",
   "metadata": {},
   "source": [
    "## Once power testing consensus is reached, we can merge weather_testing_df with power_testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a853e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_testing_df = pd.merge(weather_testing_df, power_testing_df, on=['time'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
