{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80161ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d76639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Power output HQ dataset (with only wind powercolumn)\n",
    "power_df = pd.read_csv(\"../historique-production-electricite-quebec.csv\")[[\"Date\",\"Wind\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59aa7c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated places:\n",
      "                            Date     Wind\n",
      "5476   2020-11-01T01:30:00-05:00  2737.00\n",
      "14385  2021-11-07T01:30:00-05:00  2584.00\n",
      "22988  2019-11-03T01:30:00-05:00   686.00\n",
      "28901  2022-11-06T01:30:00-05:00  2576.00\n",
      "41485  2023-03-12T03:30:00-04:00   142.97\n"
     ]
    }
   ],
   "source": [
    "#Checking duplicate 'Date' in the original dataset\n",
    "power_df_strtime = power_df\n",
    "print(\"Duplicated places:\")\n",
    "print(power_df_strtime[power_df_strtime['Date'].duplicated()])\n",
    "\n",
    "#for trouble in [5476,14385,22988,28901,41485]:\n",
    "#    print(f\"Displaying around troublesome index: {trouble}\")\n",
    "#    print(power_df.loc[trouble-2:trouble+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64fb1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format time from string to TimeStamp and converted all times to UTC\n",
    "power_df['Date'] = pd.to_datetime(power_df['Date'], utc =True)\n",
    "power_df['Date'] = power_df['Date'].apply(lambda x: x - pd.Timedelta(hours=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be7c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#power_df['TimeZone'] = power_df['Date'].apply(lambda x: x.utcoffset())\n",
    "#print(power_df['TimeZone'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c30c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df['Date'] = power_df['Date'].apply(lambda x: x.tz_convert(None)) #remove time-zone information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a9adcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8314/4099056116.py:5: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  power_df['Date'] = power_df['Date'].apply(lambda x: x.floor('H'))\n"
     ]
    }
   ],
   "source": [
    "#Sort the dataset by date\n",
    "power_df = power_df.sort_values('Date')\n",
    "\n",
    "#Replace original 'Date' column by Year:MonthDay:Hour:00 for consistant formating with weather data\n",
    "power_df['Date'] = power_df['Date'].apply(lambda x: x.floor('H'))\n",
    "\n",
    "#Adding year and month/day in the dataset\n",
    "power_df['Year'] = power_df['Date'].apply(lambda x: x.year)                     #adding a year column\n",
    "power_df['MonthDay'] = power_df['Date'].apply(lambda x: x.strftime('%m-%d'))    #adding a Month/Day column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03bda8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.datetime64('2023-12-31T23:00:00.000000000')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if the last entry in inside 2023\n",
    "np.array(power_df['Date'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd4ed969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nearby rows for duplicated timestamp: 2019-11-03 01:00:00\n",
      "                     Date   Wind  Year MonthDay\n",
      "17192 2019-11-02 22:00:00  795.0  2019    11-02\n",
      "17193 2019-11-02 23:00:00  773.0  2019    11-02\n",
      "22988 2019-11-03 01:00:00  686.0  2019    11-03\n",
      "17194 2019-11-03 01:00:00  712.0  2019    11-03\n",
      "22989 2019-11-03 02:00:00  702.0  2019    11-03\n",
      "17195 2019-11-03 03:00:00  670.0  2019    11-03\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2020-11-01 01:00:00\n",
      "                     Date    Wind  Year MonthDay\n",
      "20062 2020-10-31 22:00:00  2202.0  2020    10-31\n",
      "5474  2020-10-31 23:00:00  2459.0  2020    10-31\n",
      "5475  2020-11-01 01:00:00  2212.0  2020    11-01\n",
      "5476  2020-11-01 01:00:00  2737.0  2020    11-01\n",
      "5477  2020-11-01 02:00:00  2723.0  2020    11-01\n",
      "5478  2020-11-01 03:00:00  2400.0  2020    11-01\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2021-11-07 01:00:00\n",
      "                     Date    Wind  Year MonthDay\n",
      "31894 2021-11-06 22:00:00  2855.0  2021    11-06\n",
      "31895 2021-11-06 23:00:00  2819.0  2021    11-06\n",
      "14385 2021-11-07 01:00:00  2584.0  2021    11-07\n",
      "14383 2021-11-07 01:00:00  2689.0  2021    11-07\n",
      "31896 2021-11-07 02:00:00  2054.0  2021    11-07\n",
      "37596 2021-11-07 03:00:00  2220.0  2021    11-07\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2022-11-06 01:00:00\n",
      "                     Date    Wind  Year MonthDay\n",
      "40449 2022-11-05 22:00:00  2564.0  2022    11-05\n",
      "11379 2022-11-05 23:00:00  2634.0  2022    11-05\n",
      "28901 2022-11-06 01:00:00  2576.0  2022    11-06\n",
      "11380 2022-11-06 01:00:00  2592.0  2022    11-06\n",
      "28902 2022-11-06 02:00:00  2606.0  2022    11-06\n",
      "28903 2022-11-06 03:00:00  2720.0  2022    11-06\n",
      "\n",
      "Nearby rows for duplicated timestamp: 2023-03-12 02:00:00\n",
      "                     Date    Wind  Year MonthDay\n",
      "32815 2023-03-11 23:00:00  315.72  2023    03-11\n",
      "588   2023-03-12 00:00:00  220.03  2023    03-12\n",
      "32816 2023-03-12 01:00:00  138.07  2023    03-12\n",
      "589   2023-03-12 02:00:00  111.65  2023    03-12\n",
      "41485 2023-03-12 02:00:00  142.97  2023    03-12\n",
      "32817 2023-03-12 03:00:00  154.54  2023    03-12\n",
      "41486 2023-03-12 04:00:00  133.23  2023    03-12\n"
     ]
    }
   ],
   "source": [
    "dupes_df = power_df[power_df['Date'].duplicated(keep=False)]\n",
    "dupes_df_sorted = dupes_df.sort_values('Date')\n",
    "\n",
    "for ts in dupes_df_sorted['Date'].unique():\n",
    "    print(f\"\\nNearby rows for duplicated timestamp: {ts}\")\n",
    "    nearby = power_df[(power_df['Date'] >= ts - pd.Timedelta(hours=3)) & \n",
    "                (power_df['Date'] <= ts + pd.Timedelta(hours=2))]\n",
    "    print(nearby.sort_values('Date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084354bd",
   "metadata": {},
   "source": [
    "### The above confirms that all those duplicated values were when the time zone shifted. We would need to manually change these 5 entries.\n",
    "\n",
    "All those 01:00 will become 00:00. But I'm not sure how to deal with the duplicate 2023-03-12 02:00:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a654e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We shall manually replace them here (or some better way that we need think later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57daaec",
   "metadata": {},
   "source": [
    "# Weather files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c2bed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File names for weather data of different farms\n",
    "weather_files = os.listdir('../windfarm_weather_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just wanted to check how the dataset look by looking at the first farm\n",
    "farm_wdf = pd.read_csv(f\"../windfarm_weather_data/{weather_files[0]}\")\n",
    "\n",
    "farm_wdf['time'] = pd.to_datetime(farm_wdf['time'], utc= True)                  #convert time to Timestamp object\n",
    "farm_wdf = farm_wdf.sort_values('time')                                         #sort values using time\n",
    "\n",
    "farm_wdf['time'] = farm_wdf['time'].apply(lambda x: x - pd.Timedelta(hours=5))  #drag the times to usual days in ET\n",
    "\n",
    "farm_wdf['Year'] = farm_wdf['time'].apply(lambda x: x.year)                     #adding a year column\n",
    "farm_wdf['MonthDay'] = farm_wdf['time'].apply(lambda x: x.strftime('%m-%d'))    #adding Month/Day as a column\n",
    "\n",
    "#Remove data from 2024 as we don't have power data from 2024\n",
    "farm_wdf = farm_wdf[farm_wdf['Year'].astype(str) != '2024']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52daf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for farm_name in weather_files:\n",
    "    farm_wdf = pd.read_csv(f\"../windfarm_weather_data/{farm_name}\")\n",
    "    farm_wdf['time'] = pd.to_datetime(farm_wdf['time'])                             #convert time to Timestamp object\n",
    "    farm_wdf = farm_wdf.sort_values('time')                                         #sort values using time\n",
    "\n",
    "    farm_wdf['time'] = farm_wdf['time'].apply(lambda x: x - pd.Timedelta(hours=5))  #drag the times to usual days in ET    \n",
    "    if len(farm_wdf[farm_wdf['time'].duplicated()]):\n",
    "        print(f\"{farm_name.replace(' wind farm hourly weather 2019-2024.csv','')} has some duplicate timestamps.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ab29f",
   "metadata": {},
   "source": [
    "### Seems like weather files does not have any duplicates and have handled time-zone shifts well. Yay. \n",
    "\n",
    "I'll merge the datasets after I manually clean the power data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
